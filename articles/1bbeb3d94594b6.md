---
title: "一般化線形モデル3章前半"
emoji: "🌀"
type: "idea" # tech: 技術記事 / idea: アイデア
topics:
  - 数学
  - GLM
published: false
---

:::message
この記事は授業でのまとめのために作成したものであり、読者への価値は低いものとなっております。
:::

[一般化線形モデル](https://www.asakura.co.jp/detail.php?book_code=12860) の輪読用

第 3 章の前半部分について解説していきます。

## 3.1 二項分布

### 言葉の整理

#### キュムラント母関数

> 確率変数 $X$ に対して、$f(t)=logE[e^{tX}]$ という関数のことをキュムラント母関数と言います。また、キュムラント母関数を以下のように級数展開したときの係数 $\kappa_n$ をキュムラントと言います

> $$
> logE[e^{tX}]= \sum_{n=1}^{∞} \frac{\kappa_n}{n!}t^n
> $$
>
> 引用元: https://mathwords.net/cumulant

※ $E[e^{tX}]$は積率母関数となっている

#### 連続補正

※ まだあまり理解しやすい資料を見つけられていない

- https://ja.wikipedia.org/wiki/連続性補正

なんとなくの理解としては、離散の確率変数で連続の確率変数を近似する場合に用いられる。
似たような近似として、最近接偶数への丸め を思い浮かべた。

0.5, 1.5, ..., 9.5 これらの数字の平均を考える際に、一度整数へ丸めてから平均を取ることを考える

1. 整数へ丸めずに平均する場合 -> $(0.5 + 1.5 + \cdots + 9.5) / 10 = 5.0$
2. 四捨五入してから平均する場合 -> $(1 + 2 + \cdots + 10) / 10 = 5.5$
3. 最近接偶数への丸めをしてから平均をする場合 -> $(0 + 2 + 2 + 4 + \cdots + 10) / 10 = 5.0$

全然関係ないことではあるが、なんか調整したらうまくという話ぽい

#### 二項分布

$$
P[X=k] = \binom{n}{k}p^k(1-p)^{n-k}
$$

#### ポアソン分布

$$
P[X=k] = \frac{\lambda^ke^{-\lambda}}{k}
$$

#### 積率母関数

$$
M_X(t) = E[e^{tX}]
$$

### まとめ

- 二項分布とポアソン分布には密接な関係があり、二項分布はポアソン分布の条件付き分布として導出することができる
- 二項分布 $Y \sim Bi(n,p)$ のキュムラントは以下のようになる

  - $\kappa_1 = np$
  - $\kappa_2 = np(1-p)$
  - $\kappa_3 = n(1-p)(1-2p)$
  - $\kappa_4 = np(1-p)[1 - 6p(1-p)]$

- 二項分布は適当な条件のもとで、正規分布による近似が有効となり、$Y \sim Bi(n,p)$である時、

  $$
  Z = \frac{Y - m\pi}{\sqrt{m\pi(1-\pi)}}
  $$

  と変数変換すると、 $Z$ のキュムラントは

  - $\kappa_1 = 0$
  - $\kappa_2 = 1$
  - $\kappa_r = \mathcal{O}(m^{-1-r/2}) (r>2)$

  となり、 $r$ が大きいとキュムラントは $0$ に収束していき、標準正規分布のキュムラントと一致する

- $Y \sim Bi(m, \theta)$ で、 $\theta \to 0, m \to \infty, m\theta = \mu$ である場合、 $\theta \to 0$ における $Y$ のキュムラント母関数の極限は、平均 $\mu$ のポアソン分布のキュムラント母関数と一致し、その誤差は正規分布で近似するよりも小さい。

### 標準正規分布のキュムラントと一致する？

> 二項分布は適当な条件のもとで、正規分布による近似が有効となり、 $Y \sim Bi(n,p)$ である時、

> $$
> Z = \frac{Y - m\pi}{\sqrt{m\pi(1-\pi)}}
> $$

> と変数変換すると、 $Z$ のキュムラントは
>
> - $\kappa_1 = 0$
> - $\kappa_2 = 1$
> - $\kappa_r = \mathcal{O}(m^{-1-r/2}) (ただし r>2)$
>
> となり、 $r$ が大きいとキュムラントは $0$ に収束していき、標準正規分布のキュムラントと一致する

これが本当にそうなるか、標準正規分布のキュムラントを導出することで確かめる。

標準正規分布 $f(X) = \frac{1}{\sqrt{2\pi}} exp(-\frac{x^2}{2})$ のキュムラントを求める。

まず、 $Z$ のモーメント母関数は、

$$
    \begin{aligned}
        M_X(t)
            &= E[e^{tX}] \\
            &= \int_{-\infty}^{\infty} e^{tx} f(x) dx \\
            &= \int_{-\infty}^{\infty} e^{tx} \times \frac{1}{\sqrt{2\pi}} \times e^{-\frac{x^2}{2}} dx \\
            &= \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} e^{tx - \frac{x^2}{2}} dx \\
            &= e^{\frac{t^2}{2}} \int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi}} e^{- \frac{(x - t)^2}{2}} dx \\
            &= e^{\frac{t^2}{2}}
    \end{aligned}
$$

となるから、キュムラント母関数は

$$
    \begin{aligned}
        K_X(t)
            &= log(M_X(t)) \\
            &= \frac{t^2}{2} \\
    \end{aligned}
$$

であるから、標準積分布のキュムラントは

- $\kappa_1 = 0$
- $\kappa_2 = 1$
- $\kappa_r = 0 (ただし r>2)$

となるので、確かに、二項分布のキュムラント $\kappa_r = \mathcal{O}(m^{-1-r/2}) (ただし r>2)$ が $0$ に収束していくので、標準積分布のキュムラントと一致することがわかった

### 二項分布のキュムラント導出まで

$$
  \begin{aligned}
    M_X(t)
      &= E[e^{tX}] \\
      &= \sum_{k=0}^{n} e^{tk} P(X = k) \\
      &= \sum_{k=0}^{n} e^{tk} {}_n C_k p^k (1-p)^{n-k} \\
      &= \sum_{k=0}^{n} {}_n C_k (pe^t)^k (1-p)^{n-k} \\
      &= (pe^t + (1 - p))^n \\
      &= (pe^t + 1 - p)^n \\
\\
    K_X(t)
      &= \log M_X(t) \\
      &= \log (pe^t + 1 - p)^n \\
      &= n\log (pe^t + 1 - p) \\
\\
    K_X'(t)
      &= \frac{npe^t}{pe^t + 1 - p} \\
      &= n - \frac{n(1 - p)}{pe^t + 1 - p} \\
\\
    K_X''(t)
      &= \frac{n(1 - p)pe^t}{(pe^t + 1 - p)^2} \\
\\
    \kappa_1
      &= K_X'(0) \\
      &= np \\
\\
    \kappa_2
      &= \frac{K_X''(0)}{2!} \\
      &= \frac{np(1-p)}{2} \\
  \end{aligned}
$$

## 3.2 ロジスティック回帰モデル

### 言葉の整理

#### 線形予測子

純粋に $\beta x$ のこと

#### 連結関数（リンク関数）

よく用いられるものとしては、ロジット関数とプロビット関数がある。（p.48 を参照）

連結関数で一度変換してからモデル化することで、モデルの正確性が向上することが知られている。

#### 前向き研究・後ろ向き研究

前向き研究: 原因を用いて結果を解釈する
後ろ向き研究: 結果を用いて原因を解釈する

### まとめ

- 2 値データの解析において、ロジスティック回帰モデルが多用される理由
  - パラメータの解釈が容易
  - 後ろ向き研究に利用できる
    - ベイズの定理と組み合わせることで、発生確率が稀な場合などの事象に対しても適用することができる
- ロジスティック回帰モデルの仮定に際して、その妥当性を逸脱度などを用いて常にチェックする必要がある

## 3.3 パラメータの最尤推定

### 言葉の整理

#### チェーンルール

合成関数の微分のこと。
連鎖律。

#### 十分統計量

> 十分統計量とは、ある分布のパラメータを推定したい時に推定するに十分な情報を含んだ統計量 $T=T(X)$ のことを言います。 数式で表現すると、パラメータ $\theta$ を持つ確率分布を $P(X;θ)$ 、 $T(X)$ をある統計量としたとき、
> $$P(X=x|T(X)=t,θ)=P(X=x|T(X)=t)$$
> を満たす $T$ を十分統計量といいます。つまり、十分統計量で条件付けるとパラメータ $\theta$ よらなくなるということです。
> 引用: https://nkoda-studynote.com/statistics/sufficient_statistics/#%E5%8D%81%E5%88%86%E7%B5%B1%E8%A8%88%E9%87%8F

正直はっきりとは理解できていません。。引用先では比較的わかりやすく解説されてたので、理解の助けになると思います。

#### フィッシャーの分解定理

> つまり、標本の同時密度関数をパラメータ $\theta$ によらない関数とパラメータに依存する関数の積に分解した際に、パラメータを含む方の関数が $T(X)$ のみを含む形の分解が存在するということです。
> 引用: https://nkoda-studynote.com/statistics/sufficient_statistics/#%E3%83%95%E3%82%A3%E3%83%83%E3%82%B7%E3%83%A3%E3%83%BC%E3%83%8D%E3%82%A4%E3%83%9E%E3%83%B3%E3%81%AE%E5%88%86%E8%A7%A3%E5%AE%9A%E7%90%86

### まとめ

- パラメータに対する対数尤度に関して、いくつかのモデルを比較したい時は、連結関数部分をいじればよく、尤度部分は変わらない
- また, $\hat{β}$ の漸近分散はフィッシャー情報行列の逆行列となる
<!-- - 二値データのパラメータ推定ではロジスティック回帰モデルを用いる -->

## 3.4 逸脱度

### 言葉の整理

#### 過分散

3.6 にて解説あり

### まとめ

- モデルの適切さを評価する重要な指標として 残差逸脱度 がある
  - $残差逸脱度 = 2 × ( 最大対数尤度 − モデル最大対数尤度 )$
- モデルにより多くの共変量が追加される場合には、逸脱度は小さくなる
- 逸脱度はモデルを評価するための絶対的基準ではなく、逸脱度は複数のモデル間の比較に用いられることが多い
- 逸脱度は $\chi^2$ 分布に近似でき、検定統計量として扱いやすい性質を持つ
- モデルに変数を追加すれば、逸脱度は必ず小さくなるため、変数追加のコストと逸脱度の減少を判断する必要がある

## 3.5 スパース・データ

### 言葉の整理

#### 退化分布

退化分布
常に同じ 確率変数 返す 確率分布 を指す．

- 全ての目が同じ サイコロ
- 両側とも表と定義される コイン

### まとめ

- そのカテゴリとなる変数が非常に少ない場合、そういったデータをスパースデータという。
- スパースデータには逸脱度が求めたい数値( $\beta$ )などに依存してないか確認する必要がある。

### 疑問

- 逸脱度として使えない条件は数学的にはどういう場合になる？
  - 求めたい変数に依存している場合
  - etc...

## 参考資料

※ 2021/10/19 閲覧

- https://mathwords.net/cumulant
- https://k-san.link/characteristic-moment-cumulant/
- https://stats.biopapyrus.jp/probability/cgf.html
- https://scrapbox.io/rag-pub/%E9%80%80%E5%8C%96%E5%88%86%E5%B8%83
- https://stats.biopapyrus.jp/glm/def.html
- https://nkoda-studynote.com/statistics/sufficient_statistics
